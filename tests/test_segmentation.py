"""Test for the image classification tasks."""

import os
from typing import List
import numpy as np

import pytest

from multimedeval import EvalParams, MultiMedEval, SetupParams
from multimedeval.utils import BatcherInput, BatcherOutput

IN_GITHUB_ACTIONS = os.getenv("GITHUB_ACTIONS") == "true"


@pytest.mark.skipif(IN_GITHUB_ACTIONS, reason="Test doesn't work in Github Actions.")
@pytest.mark.parametrize("expected_dice", [(0)])
def test_refuge(expected_dice):
    """Tests the refuge task.

    Args:
        batcher_answer: Answers generated by the batcher.
        expected_dice: Expected dice score.
    """

    def zero_batcher(prompts: List[BatcherInput]) -> list:
        return [
            BatcherOutput(text="<seg0>", masks=[np.zeros((1634, 1634), dtype=np.uint8)])
            for i in prompts
        ]

    engine = MultiMedEval()

    engine.setup(
        SetupParams(
            refuge_dir="/shares/menze.dqbm.uzh/chengrun/MultiMedEvalDataset/REFUGE"
        )
    )

    results = engine.eval(["REFUGE"], zero_batcher, EvalParams(batch_size=32))

    if "REFUGE" not in results:
        # Find the element in the list that has that "name" metrics_REFUGE
        raise AssertionError()

    assert (results["REFUGE"]["Optic Disk_dice"] - expected_dice) < 0.01
    assert (results["REFUGE"]["Optic Cup_dice"] - expected_dice) < 0.01
    assert (results["REFUGE"]["all_labels_dice"] - expected_dice) < 0.01
