srun: error: ioctl(TIOCGWINSZ): Inappropriate ioctl for device
srun: error: Not using a pseudo-terminal, disregarding --pty option

Filesystems usage for user croyer ( uid 646291381 ):
[0m-------------------------------------------------------------------------------------
Directory                 Used   Limit   Used,%         Files     Limit
[0m-------------------------------------------------------------------------------------
/home/croyer             896MB[0m[1m    15GB[0m     5.8%[0m         21312[0m[1m    100000[0m
/data/croyer            [1m[33m 199GB[0m[1m   200GB[0m[1m[33m    99.1%[0m        300047[0m[1m          [0m
/scratch/croyer           55KB[0m[1m    20TB[0m     0.0%[0m            34[0m[1m          [0m
[0m
/shares/menze.dqbm.uzh    72TB[0m[1m        [0m         [0m       9425753[0m[1m          [0m
[0m-------------------------------------------------------------------------------------

!! Please note: the scratch filesystem is intended only for temporary storage.
   Files in /scratch/croyer that have not been accessed in more than 30 days
   may be automatically deleted.

Wed Dec  6 18:54:27 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:07.0 Off |                    0 |
| N/A   31C    P8     9W /  70W |      2MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
[nltk_data] Downloading package stopwords to /home/croyer/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!


Running MultiMedBenchmark with Params(usepytorch=True, seed=42, batch_size=64, run_name='run 2023-12-06 18:54:27.303736')
RadGraph already downloaded
Chexbert already downloaded
***** Benchmarking : MIMIC_CXR report generation *****
Running inference:   0%|          | 0/55 [00:00<?, ?it/s]/shares/menze.dqbm.uzh/corentin/RadGraph/scorers/RadGraph/dygie/data/dataset_readers/dygie.py:192: UserWarning: Document 0 has a sentence with a single token or no tokens. This may break the modeling code.
  warnings.warn(msg)
/shares/menze.dqbm.uzh/corentin/RadGraph/scorers/RadGraph/allennlp/nn/util.py:1467: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  return torch.cuda.LongTensor(size, device=device).fill_(1).cumsum(0) - 1
Running inference:   0%|          | 0/55 [00:03<?, ?it/s]

Tokenizing report impressions. All reports are cut off at 512 tokens.
  0%|          | 0/64 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:00<00:00, 722.46it/s]
Using 1 GPUs!

Begin report impression labeling. The progress bar counts the # of batches completed:
The batch size is 18
  0%|          | 0/4 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.90it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.68it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.51it/s]

Tokenizing report impressions. All reports are cut off at 512 tokens.
  0%|          | 0/64 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:00<00:00, 10449.03it/s]
Using 1 GPUs!

Begin report impression labeling. The progress bar counts the # of batches completed:
The batch size is 18
  0%|          | 0/4 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 105.19it/s]
torch.Size([64])
{'type': 'json', 'name': 'metrics_MIMIC_CXR report generation', 'value': {'bleu1': 0.0, 'bleu4': 0.0, 'rougeL': {'rougeL_fmeasure': tensor(0.), 'rougeL_precision': tensor(0.), 'rougeL_recall': tensor(0.)}, 'f1-radgraph': 0.0, 'CheXBert vector similarity': 0.12085098773241043}}
